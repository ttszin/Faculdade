# -*- coding: utf-8 -*-
"""regressao_polinomial_134498.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wgB2PBCFIM6Vlqr3aFIPNDHlO4Miurgg

#Autor: Matheus Teixeira de Souza

#Resumo: A regressão linear é uma técnica que obtém um melhor ajuste da reta com os dados obtidos. Ela prevê o valor de dados desconhecidos utilizando outro conjunto de valores conhecidos.  

#É uma técnica estatística usada para modelar a relação entre uma variável dependente e uma ou mais variáveis ​​independentes. Ele assume uma relação não linear adicionando termos polinomiais à equação de regressão.

#Modo de funcionamento:

**Primeiramente, devemos preparar os dados para que não haja falta de dados
Após isso, é necessário escolher o grau apropriado para o polinômio, um grau elevado pode levar ao overfitting.**

**O próximo passo é treinar o modelo de regressão polinomial, estimando os coeficientes dos termos polinomiais, utilizando o mínimos quadrados.**

**Após a avaliação do modelo é importante realizar a medição de erros como erro padrão e coeficiente coeficiente de correlação para verificar a precisão dos restultados.**

#Por exemplo, tendo dados sobre despesas e receita do ano passado, as técnicas de regressão linear analisam tais dados e determinam que as despesas são a metade da renda atual. Assim, calculando uma despesa futura que ainda não era conhecida, utilizando uma renda futura também desconhecida.
"""

import numpy as np
import matplotlib.pyplot as plt

#OBS: Esse código possui criação de gráficos para uma observação mais clara do método (assim como nos slides)

"""
    Implementação da Regressão linear para estimar o valor da função em um ponto z.

    Parâmetros:
    x : Lista com as os valores das abcissas obtidas.
    y : Lista com as os valores das ordenadas obtidas.

    O que é retornado?
    O Polinômio ajustado, o erro padrão e o coeficiente de correlação.
"""


# Dados fornecidos
xi = np.array([0, 1, 2, 3, 4, 5])  # Valores das abcissas
yi = np.array([2.1, 7.7, 13.6, 27.2, 40.9, 61.1])  # Valores das ordenadas

# Número de pontos
n = len(xi)  # Calcula o número total de pontos

# Construção da matriz e vetor para o sistema linear
# X é a matriz que contém termos para x^2, x e o termo constante
X = np.vstack([xi**2, xi, np.ones(n)]).T
Y = yi  # Vetor de valores y

# Resolução do sistema linear para encontrar os coeficientes a0, a1, a2
# np.linalg.lstsq resolve o sistema de equações lineares usando o método dos mínimos quadrados
coeficientes = np.linalg.lstsq(X, Y, rcond=None)[0]

# Coeficientes do polinômio: a0 + a1*x + a2*x^2
a2, a1, a0 = coeficientes

# Calculando os valores ajustados para o polinômio de segundo grau
y_pred = a0 + a1 * xi + a2 * xi**2

# Cálculo do erro padrão da estimativa
# ss_res é a soma dos quadrados dos resíduos
ss_res = np.sum((yi - y_pred)**2)
# O erro padrão é a raiz quadrada da soma dos quadrados dos resíduos dividida pelos graus de liberdade
erro_padrao = np.sqrt(ss_res / (n - 3))  # n - 3 porque temos 3 coeficientes (a0, a1, a2)

# Cálculo do coeficiente de correlação (R²)
# ss_tot é a soma total dos quadrados
ss_tot = np.sum((yi - np.mean(yi))**2)
# R² é a proporção da variação explicada pelo modelo
r2 = 1 - (ss_res / ss_tot)

# Exibindo os resultados
print(f"Polinômio ajustado: y = {a2:.4f}x^2 + {a1:.4f}x + {a0:.4f}")
print(f"Erro padrão da estimativa: {erro_padrao:.4f}")
print(f"Coeficiente de correlação (R²): {r2:.4f}")

# Plotando os dados e o polinômio ajustado
plt.scatter(xi, yi, color='red', label='Dados Originais')  # Plota os pontos originais
plt.plot(xi, y_pred, color='blue', label='Polinômio Ajustado')  # Plota o polinômio ajustado
plt.xlabel('x')  # Rótulo do eixo x
plt.ylabel('y')  # Rótulo do eixo y
plt.title('Ajuste Polinomial de Segundo Grau')  # Título do gráfico
plt.legend()  # Adiciona a legenda
plt.grid(True)  # Adiciona uma grade ao gráfico
plt.show()  # Exibe o gráfico